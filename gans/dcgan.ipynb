{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN - Deep Convolutional GANs\n",
    "\n",
    "- [DCGAN paper link](https://arxiv.org/abs/1511.06434)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCGAN (Deep Convolutional Generative Adversarial Network) has several unique features that distinguish it from traditional GAN architectures. Here are some of the key characteristics of DCGAN:\n",
    "\n",
    "- Convolutional Architecture: DCGAN utilizes convolutional layers in both the generator and discriminator networks instead of fully connected layers. This allows the model to effectively capture spatial information and generate high-resolution images.\n",
    "\n",
    "- Strided Convolutions and Transposed Convolutions: DCGAN uses strided convolutions in the discriminator to downsample the input and transposed convolutions in the generator to upsample the noise input. This helps in learning hierarchical representations and generating higher-resolution images.\n",
    "\n",
    "- Batch Normalization: DCGAN applies batch normalization to the activations in both the generator and discriminator networks. It helps in stabilizing the training process and accelerates convergence by normalizing the inputs to each layer.\n",
    "\n",
    "- LeakyReLU Activation: DCGAN employs LeakyReLU activation in the discriminator network instead of traditional ReLU. LeakyReLU allows for non-zero gradients for negative inputs, preventing the \"dying ReLU\" problem and improving the flow of gradients during training.\n",
    "\n",
    "- No Fully Connected Layers: DCGAN does not use fully connected layers in the discriminator or generator. Instead, it relies on convolutional layers and global pooling to reduce the spatial dimensions of the activations.\n",
    "\n",
    "- Random Noise Input: DCGAN takes random noise as input to the generator network. This noise vector is typically sampled from a uniform or normal distribution and serves as the source of randomness for generating diverse images.\n",
    "\n",
    "These unique characteristics make DCGAN well-suited for generating high-quality and realistic images. It has been widely used in various applications, including image synthesis, image-to-image translation, and style transfer.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Model\n",
    "def Generator():\n",
    "\n",
    "    # input \n",
    "    input = tf.keras.Input(shape=(100,))   # accepts the shape of latent dimensions and batch size\n",
    "\n",
    "    # Stacking layers\n",
    "    dense_1 = tf.keras.layers.Dense(units=7*7*256, use_bias=False)(input)    # transform the input noise to higher dimensions representations\n",
    "    reshape = tf.keras.layers.Reshape((7,7,256))(dense_1)      #  Reshapes the tensor to (7, 7, 256)\n",
    "\n",
    "    conv2dT_1 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(5,5),\n",
    "                                                 strides=(1,1),padding=\"same\", use_bias=False)(reshape) # Performs transpose convolution on the input tensor, increasing its spatial dimensions.\n",
    "    batchnorm_1 = tf.keras.layers.BatchNormalization()(conv2dT_1)\n",
    "    leakyrelu_1 = tf.keras.layers.LeakyReLU(alpha=0.01)(batchnorm_1)\n",
    "\n",
    "\n",
    "    conv2dT_2 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(5,5),\n",
    "                                                 strides=(2,2),padding=\"same\", use_bias=False)(leakyrelu_1) \n",
    "    batchnorm_2 = tf.keras.layers.BatchNormalization()(conv2dT_2)\n",
    "    leakyrelu_2 = tf.keras.layers.LeakyReLU(alpha=0.01)(batchnorm_2)\n",
    "\n",
    "    # Output layer with tanh activation\n",
    "    generated_image = tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False,\n",
    "                                             activation='tanh')(leakyrelu_2)\n",
    "    \n",
    "    # Defining Model\n",
    "    model = tf.keras.Model(inputs=input, outputs=generated_image)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 12544)             1254400   \n",
      "                                                                 \n",
      " reshape_11 (Reshape)        (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_33 (Conv2D  (None, 7, 7, 128)        819200    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 7, 7, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_50 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_34 (Conv2D  (None, 14, 14, 64)       204800    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 14, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_51 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_35 (Conv2D  (None, 28, 28, 1)        1600      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,280,768\n",
      "Trainable params: 2,280,384\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = Generator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrminator \n",
    "\n",
    "def Discriminator():\n",
    "\n",
    "    # input\n",
    "    input = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "    # stacking layers\n",
    "    conv_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3))(input)\n",
    "    batchnorm_1 = tf.keras.layers.BatchNormalization()(conv_1)\n",
    "    leakyrelu_1 = tf.keras.layers.LeakyReLU(alpha=0.01)(batchnorm_1)\n",
    "    droput_1 = tf.keras.layers.Dropout(rate=0.3)(leakyrelu_1)\n",
    "\n",
    "    conv_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3))(droput_1)\n",
    "    batchnorm_2 = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "    leakyrelu_2 = tf.keras.layers.LeakyReLU(alpha=0.01)(batchnorm_2)\n",
    "    droput_2 = tf.keras.layers.Dropout(rate=0.3)(leakyrelu_2)\n",
    "\n",
    "    conv_3 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3))(droput_2)\n",
    "    batchnorm_3 = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "    leakyrelu_3 = tf.keras.layers.LeakyReLU(alpha=0.01)(batchnorm_3)\n",
    "    droput_3 = tf.keras.layers.Dropout(rate=0.3)(leakyrelu_3)\n",
    "\n",
    "    # Flatten\n",
    "    flatten = tf.keras.layers.Flatten()(droput_3)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(flatten)\n",
    "\n",
    "\n",
    "    # Defining Model\n",
    "    discriminator = tf.keras.models.Model(inputs=input, outputs=output)\n",
    "\n",
    "    return discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 26, 26, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_52 (LeakyReLU)  (None, 26, 26, 64)        0         \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 26, 26, 64)        0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 24, 24, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_53 (LeakyReLU)  (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 22, 22, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 22, 22, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_54 (LeakyReLU)  (None, 22, 22, 256)       0         \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 22, 22, 256)       0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 123904)            0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 123905    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 495,361\n",
      "Trainable params: 494,465\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d = Discriminator()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.random.normal((32,28,28,1))\n",
    "\n",
    "d.predict(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Noise\n",
    "\n",
    "def generate_noise(latent_dimensions=100, batch_size=32):\n",
    "\n",
    "    return tf.random.normal((batch_size,latent_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "cross_entrophy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "\n",
    "# Generator Loss\n",
    "def generator_loss(generator_output):\n",
    "\n",
    "    return cross_entrophy(tf.ones_like(generator_output), generator_output)\n",
    "\n",
    "# Discriminator loss\n",
    "def discriminator_loss(fake_images, real_images):\n",
    "\n",
    "    fake_loss = cross_entrophy(tf.zeros_like(fake_images), fake_images)\n",
    "    real_loss = cross_entrophy(tf.ones_like(real_images),real_images )\n",
    "\n",
    "    loss = fake_loss + real_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, compare the discriminators decisions on the generated images to an array of 1s.\n",
    "\n",
    "- This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "epochs = 50\n",
    "latent_dimensions = 100\n",
    "batch_size = 64\n",
    "BUFFER_SIZE = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data Loading & preprocessing\n",
    "\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step\n",
    "\n",
    "generator = Generator()\n",
    "discrminator = Discriminator()\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "\n",
    "    # generate noise\n",
    "    noise = generate_noise(latent_dimensions=100, batch_size=batch_size)\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "\n",
    "        # generator takes input as noise and generate image\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        # discrminator classify the fake and real images\n",
    "        fake_clasiifier = discrminator(generated_images, training=True)\n",
    "        real_classifier = discrminator(images, training=True)\n",
    "\n",
    "        # Caluclate loss\n",
    "        gen_loss = generator_loss(generated_images)\n",
    "        disc_loss = discriminator_loss(fake_clasiifier, real_classifier)\n",
    "\n",
    "    # Caluclate Gradients\n",
    "    generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    discrminator_gradients = disc_tape.gradient(disc_loss, discrminator.trainable_variables)\n",
    "\n",
    "    # optimizer step\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discrminator_gradients, discrminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "\n",
    "def train(dataset, epochs=20):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        if epoch:\n",
    "\n",
    "            print(f\"Current epoch is {epoch}\")\n",
    "\n",
    "            # Generate samples after each epoch\n",
    "            random_latent_vectors = tf.random.normal([10, 100])\n",
    "            generated_images = generator(random_latent_vectors, training=False)\n",
    "\n",
    "            # Reshape the generated images\n",
    "            generated_images = generated_images.numpy().reshape(-1, 28, 28)\n",
    "\n",
    "            # Display the generated images\n",
    "            plt.figure(figsize=(10, 1))\n",
    "            for i in range(10):\n",
    "                plt.subplot(1, 10, i + 1)\n",
    "                plt.imshow(generated_images[i], cmap='gray')\n",
    "                plt.axis('off')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
