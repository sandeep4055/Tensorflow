{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"text-align:center;color:DodgerBlue;\"> Introduction to Tensors </h1> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In TensorFlow, a tensor is a multi-dimensional array or a list of numbers, which can be used to represent data in a variety of formats, such as images, audio, video, and text. Tensors are the fundamental building blocks of TensorFlow computations.\n",
    "\n",
    "##### Tensors have several important properties, including their data type, shape, and rank:\n",
    "\n",
    "- Data type: Each element of a tensor has a data type, such as float32, int32, or bool. TensorFlow supports a wide range of data types, and the data type of a tensor is determined when the tensor is created.\n",
    "\n",
    "- Shape: The shape of a tensor defines the number of dimensions and the size of each dimension. For example, a 3x4 matrix has a shape of (3, 4), while a 3x4x2 tensor has a shape of (3, 4, 2). The shape of a tensor can be changed using functions like tf.reshape().\n",
    "\n",
    "- Rank: The rank of a tensor is the number of dimensions it has. For example, a scalar (single number) has a rank of 0, a vector has a rank of 1, a matrix has a rank of 2, and so on.\n",
    "\n",
    "Tensors in TensorFlow can be created using various functions, including tf.constant(), tf.Variable(), tf.placeholder(), and tf.random. Once created, tensors can be manipulated and transformed using a wide range of TensorFlow operations, such as element-wise operations, matrix operations, and convolutional operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors with tf.constant()\n",
    "<p> As mentioned before, in general, you usually won't create tensors yourself. This is because TensorFlow has modules built-in (such as tf.io and tf.data) which are able to read your data sources and automatically convert them to tensors and then later on, neural network models will process these for us.\n",
    "\n",
    "But for now, because we're getting familar with tensors themselves and how to manipulate them, we'll see how we can create them ourselves.</p>\n",
    "\n",
    "<p> We'll begin by using tf.constant().</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a scalar (rank 0 tensor)\n",
    "scalar = tf.constant(10)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scalar is known as a rank 0 tensor. Because it has no dimensions (it's just a number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of dimensions of a tensor (ndim stands for number of dimensions)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector (more than 0 dimensions)\n",
    "vector = tf.constant([10, 10])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of dimensions of our vector tensor\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 7, 10]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix (more than 1 dimension)\n",
    "matrix = tf.constant([[10, 7],\n",
    "                      [7, 10]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, TensorFlow creates tensors with either an int32 or float32 datatype.\n",
    "\n",
    "This is known as [32-bit precision](https://en.wikipedia.org/wiki/Precision_(computer_science) (the higher the number, the more precise the number, the more space it takes up on your computer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[10.,  7.],\n",
       "       [ 3.,  2.],\n",
       "       [ 8.,  9.]], dtype=float16)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create another matrix and define the datatype\n",
    "another_matrix = tf.constant([[10., 7.],\n",
    "                              [3., 2.],\n",
    "                              [8., 9.]], dtype=tf.float16) # specify the datatype with 'dtype'\n",
    "another_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even though another_matrix contains more numbers, its dimensions stay the same\n",
    "another_matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How about a tensor? (more than 2 dimensions, although, all of the above items are also technically tensors)\n",
    "tensor = tf.constant([[[1, 2, 3],\n",
    "                       [4, 5, 6]],\n",
    "                      [[7, 8, 9],\n",
    "                       [10, 11, 12]],\n",
    "                      [[13, 14, 15],\n",
    "                       [16, 17, 18]]])\n",
    "tensor\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This is known as a rank 3 tensor (3-dimensions), however a tensor can have an arbitrary (unlimited) amount of dimensions.</p>\n",
    "\n",
    "<p> For example, you might turn a series of images into tensors with shape (224, 224, 3, 32), where: </p>\n",
    "<ul>\n",
    "<li>224, 224 (the first 2 dimensions) are the height and width of the images in pixels.</li>\n",
    "<li>3 is the number of colour channels of the image (red, green blue).</li>\n",
    "<li>32 is the batch size (the number of images a neural network sees at any one time).</li>\n",
    "</ul>\n",
    "<p>All of the above variables we've created are actually tensors. But you may also hear them referred to as their different names (the ones we gave them):</p>\n",
    "\n",
    "<ul>\n",
    "<li> scalar: a single number.</li> \n",
    "<li> vector: a number with direction (e.g. wind speed with direction).</li> \n",
    "<li> matrix: a 2-dimensional array of numbers.</li> \n",
    "<li> tensor: an n-dimensional arrary of numbers (where n can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector).</li> \n",
    "</ul>\n",
    "<p>To add to the confusion, the terms matrix and tensor are often used interchangably.</p>\n",
    "\n",
    "<p> Going forward since we're using TensorFlow, everything we refer to and use will be tensors.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors with tf.Variable()\n",
    "\n",
    "<p>The difference between tf.Variable() and tf.constant() is tensors created with tf.constant() are immutable (can't be changed, can only be used to create a new tensor), where as, tensors created with tf.Variable() are mutable (can be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7])>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7])>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the same tensor with tf.Variable() and tf.constant()\n",
    "changeable_tensor = tf.Variable([10, 7])\n",
    "unchangeable_tensor = tf.constant([10, 7])\n",
    "changeable_tensor, unchangeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to change one of the elements of the changable tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([7, 7])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ASSIGN is used to change element in tensor\n",
    "changeable_tensor[0].assign(7)\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Will error (can't change tf.constant())\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m unchangeable_tensor[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49massign(\u001b[39m7\u001b[39m)\n\u001b[0;32m      3\u001b[0m unchangeable_tensor\n",
      "File \u001b[1;32mc:\\Users\\vamsi\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:446\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mravel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtranspose\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclip\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    438\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtolist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    439\u001b[0m   \u001b[39m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m    440\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    441\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m    442\u001b[0m \u001b[39m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[0;32m    443\u001b[0m \u001b[39m    from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[0;32m    444\u001b[0m \u001b[39m    np_config.enable_numpy_behavior()\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"\u001b[39m)\n\u001b[1;32m--> 446\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "# Will error (can't change tf.constant())\n",
    "unchangeable_tensor[0].assign(7)\n",
    "unchangeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which one should you use? tf.constant() or tf.Variable()?\n",
    "\n",
    "It will depend on what your problem requires. However, most of the time, TensorFlow will automatically choose for you (when loading data or modelling data)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating random tensors\n",
    "Random tensors are tensors of some abitrary size which contain random numbers.\n",
    "\n",
    "Why would you want to create random tensors?\n",
    "\n",
    "This is what neural networks use to intialize their weights (patterns) that they're trying to learn in the data.\n",
    "\n",
    "For example, the process of a neural network learning often involves taking a random n-dimensional array of numbers and refining them until they represent some kind of pattern (a compressed way to represent the original data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create random tensors by using the tf.random.Generator class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193765, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193765, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two random (but the same) tensors\n",
    "random_1 = tf.random.Generator.from_seed(42) # set the seed for reproducibility\n",
    "random_1 = random_1.normal(shape=(3, 2)) # create tensor from a normal distribution \n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape=(3, 2))\n",
    "\n",
    "# Are they equal?\n",
    "random_1, random_2, random_1 == random_2\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random tensors we've made are actually pseudorandom numbers (they appear as random, but really aren't).\n",
    "\n",
    "If we set a seed we'll get the same random numbers (if you've ever used NumPy, this is similar to np.random.seed(42)).\n",
    "\n",
    "Setting the seed says, \"hey, create some random numbers, but flavour them with X\" (X is the seed).\n",
    "\n",
    "What do you think will happen when we change the seed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193765, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[ 0.2730574 , -0.29925638],\n",
       "        [-0.3652325 ,  0.61883307],\n",
       "        [-1.0130816 ,  0.2829171 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[False, False],\n",
       "        [False, False],\n",
       "        [False, False]])>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two random (and different) tensors\n",
    "random_3 = tf.random.Generator.from_seed(42)\n",
    "random_3 = random_3.normal(shape=(3, 2))\n",
    "random_4 = tf.random.Generator.from_seed(11)\n",
    "random_4 = random_4.normal(shape=(3, 2))\n",
    "\n",
    "# Check the tensors and see if they are equal\n",
    "random_3, random_4, random_1 == random_3, random_3 == random_4\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you wanted to shuffle the order of a tensor?\n",
    "\n",
    "Wait, why would you want to do that?\n",
    "\n",
    "Let's say you working with 15,000 images of cats and dogs and the first 10,000 images of were of cats and the next 5,000 were of dogs. This order could effect how a neural network learns (it may overfit by learning the order of the data), instead, it might be a good idea to move your data around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 2,  5],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle a tensor (valuable for when you want to shuffle your data)\n",
    "not_shuffled = tf.constant([[10, 7],\n",
    "                            [3, 4],\n",
    "                            [2, 5]])\n",
    "# Gets different results each time\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 2,  5],\n",
       "       [ 3,  4],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle in the same order every time using the seed parameter (won't acutally be the same)\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle in the same order every time\n",
    "\n",
    "# Set the global random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set the operation random seed\n",
    "tf.random.shuffle(not_shuffled, seed=42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 3,  4],\n",
       "       [ 2,  5],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the global random seed\n",
    "tf.random.set_seed(42) # if you comment this out you'll get different results\n",
    "\n",
    "# Set the operation random seed\n",
    "tf.random.shuffle(not_shuffled, seed=21)\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ways to make tensors\n",
    "Though you might rarely use these (remember, many tensor operations are done behind the scenes for you), you can use tf.ones() to create a tensor of all ones and tf.zeros() to create a tensor of all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 10, 20), dtype=float32, numpy=\n",
       "array([[[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a tensor of all ones\n",
    "tf.ones(shape=(3, 2, 10, 20)) #4D TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a tensor of all zeros\n",
    "tf.zeros(shape=(3, 2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can also turn NumPy arrays in into tensors.\n",
    "\n",
    "Remember, the main difference between tensors and NumPy arrays is that tensors can be run on GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24]),\n",
       " <tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy=\n",
       " array([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]],\n",
       " \n",
       "        [[13, 14, 15],\n",
       "         [16, 17, 18],\n",
       "         [19, 20, 21],\n",
       "         [22, 23, 24]]])>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_A = np.arange(1, 25, dtype=np.int32) # create a NumPy array between 1 and 25\n",
    "A = tf.constant(numpy_A,  \n",
    "                shape=[2, 4, 3]) # note: the shape total (2*4*3) has to match the number of elements in the array\n",
    "numpy_A, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting information from tensors (shape, rank, size)\n",
    "There will be times when you'll want to get different pieces of information from your tensors, in particuluar, you should know the following tensor vocabulary:\n",
    "<ul>\n",
    "<li>Shape: The length (number of elements) of each of the dimensions of a tensor.\n",
    "<li>Rank: The number of tensor dimensions. A scalar has rank 0, a vector has rank 1, a matrix is rank 2, a tensor has rank n.\n",
    "<li>Axis or Dimension: A particular dimension of a tensor.\n",
    "<li>Size: The total number of items in the tensor.\n",
    "</ul>\n",
    "You'll use these especially when you're trying to line up the shapes of your data to the shapes of your model. For example, making sure the shape of your image tensors are the same shape as your models input layer.\n",
    "\n",
    "We've already seen one of these before using the ndim attribute. Let's see the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 4 tensor (4 dimensions)\n",
    "rank_4_tensor = tf.zeros([2, 3, 4, 5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of every element: <dtype: 'float32'>\n",
      "Number of dimensions (rank): 4\n",
      "Shape of tensor: (2, 3, 4, 5)\n",
      "Elements along axis 0 of tensor: 2\n",
      "Elements along last axis of tensor: 5\n",
      "Total number of elements (2*3*4*5): 120\n"
     ]
    }
   ],
   "source": [
    "# Get various attributes of tensor\n",
    "print(\"Datatype of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank):\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along last axis of tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements (2*3*4*5):\", tf.size(rank_4_tensor).numpy()) # .numpy() converts to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 2 items of each dimension\n",
    "rank_4_tensor[:2, :2, :2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the dimension from each index except for the final one\n",
    "rank_4_tensor[:1, :1, :1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 4])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 2 tensor (2 dimensions)\n",
    "rank_2_tensor = tf.constant([[10, 7],\n",
    "                             [3, 4]])\n",
    "\n",
    "# Get the last item of each row\n",
    "rank_2_tensor[:, -1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[10,  7],\n",
       "        [ 3,  4]])>,\n",
       " <tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       " array([[[10],\n",
       "         [ 7]],\n",
       " \n",
       "        [[ 3],\n",
       "         [ 4]]])>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension (to the end)\n",
    "rank_3_tensor = rank_2_tensor[..., tf.newaxis] # in Python \"...\" means \"all dimensions prior to\"\n",
    "rank_2_tensor, rank_3_tensor # shape (2, 2), shape (2, 2, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can achieve the same using tf.expand_dims()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=-1) # \"-1\" means last axis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating tensors (tensor operations)\n",
    "Finding patterns in tensors (numberical representation of data) requires manipulating them.\n",
    "\n",
    "Again, when building models in TensorFlow, much of this pattern discovery is done for you.\n",
    "\n",
    "### Basic operations\n",
    "You can perform many of the basic mathematical operations directly on tensors using Python operators such as, +, -, *."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can add values to a tensor using the addition operator\n",
    "tensor = tf.constant([[10, 7], [3, 4]])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used tf.constant(), the original tensor is unchanged (the addition gets done on a copy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor unchanged\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication (known as element-wise multiplication)\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 0, -3],\n",
       "       [-7, -6]])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract\n",
    "tensor - 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the equivalent TensorFlow function. Using the TensorFlow function (where possible) has the advantage of being speed up later down the line when running as part of a TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the tensorflow function equivalent of the '*' (multiply) operator\n",
    "tf.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The original tensor is still unchanged\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix mutliplication\n",
    "One of the most common operations in machine learning algorithms is matrix multiplication.\n",
    "\n",
    "TensorFlow implements this matrix multiplication functionality in the tf.matmul() method.\n",
    "\n",
    "The main two rules for matrix multiplication to remember are:\n",
    "<ul>\n",
    "<li>\n",
    "The inner dimensions must match:\n",
    "<li>\n",
    "The resulting matrix has the shape of the outer dimensions:\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 3  4]], shape=(2, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication in TensorFlow\n",
    "print(tensor)\n",
    "tf.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication with Python operator '@'\n",
    "tensor @ tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "<ul>\n",
    "<li>\n",
    "tf.reshape() - allows us to reshape a tensor into a defined shape.\n",
    "<li>\n",
    "tf.transpose() - switches the dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 3],\n",
       "       [1, 4],\n",
       "       [2, 3]])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1,3], \n",
    "                 [1,4],\n",
    "                 [2,3]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3), dtype=int32, numpy=\n",
       "array([[[1, 3, 1],\n",
       "        [4, 2, 3]]])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x,shape=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 2), dtype=int32, numpy=\n",
       "array([[[1, 3],\n",
       "        [1, 4],\n",
       "        [2, 3]]])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x,shape=(1,3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 6), dtype=int32, numpy=array([[[1, 3, 1, 4, 2, 3]]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x,shape=(1,1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 2],\n",
       "       [3, 4, 3]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose (3,2) >> (2,3)\n",
    "tf.transpose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[ 2.0620718 ,  4.389797  ,  4.01282   , -2.121596  ],\n",
       "       [ 0.444628  , -1.5793631 , -1.9213755 , -1.9311769 ],\n",
       "       [ 0.1918219 ,  0.8305587 ,  6.957326  , -0.83640313]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose in matmul\n",
    "a = tf.random.normal(shape=(3,5))\n",
    "b = tf.random.normal(shape=(4,5))\n",
    "\n",
    "tf.matmul(a, b, transpose_a=False, transpose_b=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dot product\n",
    "\n",
    "Multiplying matrices by eachother is also referred to as the dot product.\n",
    "\n",
    "You can perform the tf.matmul() operation using tf.tensordot()."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dot product is a special case of matrix multiplication where both matrices are vectors (i.e., one-dimensional arrays). The dot product of two vectors can be computed as the sum of the element-wise products of the vectors.\n",
    "\n",
    "- Matrix multiplication, on the other hand, is a more general operation that can be applied to matrices of any shape. It involves multiplying the rows of the first matrix by the columns of the second matrix, and summing the products.\n",
    "\n",
    "- One key difference between dot product and matrix multiplication is the output shape. The dot product of two vectors results in a scalar, whereas the result of matrix multiplication is a matrix whose shape depends on the shape of the input matrices.\n",
    "\n",
    "- Another difference is that matrix multiplication is not commutative, whereas the dot product is. In other words, if you have two matrices A and B, the result of A * B may not be the same as the result of B * A, whereas the dot product of two vectors a and b is the same as the dot product of b and a.\n",
    "\n",
    "- In deep learning and machine learning, matrix multiplication is commonly used to represent linear transformations between layers of a neural network. The dot product is used in various operations, such as computing the similarity between two vectors or in attention mechanisms.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **tf.matmul** and **tf.tensordot** are both TensorFlow functions for performing tensor multiplication, but they differ in how they perform the multiplication.\n",
    "\n",
    "- tf.matmul is used for matrix multiplication between two tensors, and it only works on tensors with rank >= 2. It performs matrix multiplication according to the standard mathematical rules, which involve multiplying the rows of the first matrix by the columns of the second matrix. The two input tensors must have compatible shapes for matrix multiplication (i.e., the inner dimensions must match).\n",
    "\n",
    "Here's an example of using tf.matmul:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# create two matrices\n",
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "b = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "# compute matrix multiplication using tf.matmul\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c.numpy())  # [[19 22]\n",
    "                  #  [43 50]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.tensordot, on the other hand, is a more general function that can be used for various types of tensor multiplication, including matrix multiplication. It allows you to specify which axes to multiply along and how to combine the remaining axes. The two input tensors can have any rank.\n",
    "\n",
    "Here's an example of using tf.tensordot for matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# create two matrices\n",
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "b = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "# compute matrix multiplication using tf.tensordot\n",
    "c = tf.tensordot(a, b, axes=[[1], [0]])\n",
    "\n",
    "print(c.numpy())  # [[19 22]\n",
    "                  #  [43 50]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we specify that we want to multiply the second axis of a with the first axis of b, which correspond to the rows and columns, respectively, in matrix multiplication. The resulting tensor has the remaining axes of the two input tensors, which is what we want for matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the datatype of a tensor\n",
    "Sometimes you'll want to alter the default datatype of your tensor.\n",
    "\n",
    "This is common when you want to compute using less precision (e.g. 16-bit floating point numbers vs. 32-bit floating point numbers).\n",
    "\n",
    "Computing with less precision is useful on devices with less computing capacity such as mobile devices (because the less bits, the less space the computations require).\n",
    "\n",
    "You can change the datatype of a tensor using tf.cast()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.7, 7.4], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 7])>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor with default datatype (float32)\n",
    "B = tf.constant([1.7, 7.4])\n",
    "\n",
    "# Create a new tensor with default datatype (int32)\n",
    "C = tf.constant([1, 7])\n",
    "B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change from float32 to float16 (reduced precision)\n",
    "B = tf.cast(B, dtype=tf.float16)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 7.], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change from int32 to float32\n",
    "C = tf.cast(C, dtype=tf.float32)\n",
    "C"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the absolute value\n",
    "Sometimes you'll want the absolute values (all values are positive) of elements in your tensors.\n",
    "\n",
    "To do so, you can use tf.abs()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ -7.5, -10. ], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor with negative values\n",
    "D = tf.constant([-7.5, -10])\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 7.5, 10. ], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the absolute values\n",
    "tf.abs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum (aggregation)\n",
    "You can quickly aggregate (perform a calculation on a whole tensor) tensors to find things like the minimum value, maximum value, mean and sum of all the elements.\n",
    "\n",
    "To do so, aggregation methods typically have the syntax reduce()_[action], such as:\n",
    "<ul>\n",
    "<li>tf.reduce_min() - find the minimum value in a tensor.\n",
    "<li>tf.reduce_max() - find the maximum value in a tensor (helpful for when you want to find the highest prediction probability).\n",
    "<li>tf.reduce_mean() - find the mean of all elements in a tensor.\n",
    "<li>tf.reduce_sum() - find the sum of all elements in a tensor.\n",
    "</ul>\n",
    "Note: typically, each of these is under the math module, e.g. tf.math.reduce_min() but you can use the alias tf.reduce_min().\n",
    "Let's see them in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([16, 46, 19, 38, 49, 10, 33, 26, 24, 17, 14, 28, 39, 15, 67, 29, 40,\n",
       "       24, 82, 75, 87, 75, 85, 33, 95, 43, 45, 91, 79,  5, 71, 67, 72,  5,\n",
       "       21, 68, 36, 83, 13, 90, 97,  8, 13,  9, 32, 56, 88, 50, 76, 54])>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with 50 random values between 0 and 100\n",
    "E = tf.constant(np.random.randint(low=0, high=100, size=50))\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the minimum\n",
    "tf.reduce_min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=97>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the maximum\n",
    "tf.reduce_max(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=46>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean\n",
    "tf.reduce_mean(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2338>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "tf.reduce_sum(E)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find the standard deviation (tf.reduce_std()) and variance (tf.reduce_variance()) of elements in a tensor using similar methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Finding the positional maximum and minimum\n",
    "How about finding the position a tensor where the maximum value occurs?\n",
    "\n",
    "This is helpful when you want to line up your labels (say ['Green', 'Blue', 'Red']) with your prediction probabilities tensor (e.g. [0.98, 0.01, 0.01]).\n",
    "\n",
    "In this case, the predicted label (the one with the highest prediction probability) would be 'Green'.\n",
    "\n",
    "You can do the same for the minimum (if required) with the following:\n",
    "<ul>\n",
    "<li>tf.argmax() - find the position of the maximum element in a given tensor.\n",
    "<li>tf.argmin() - find the position of the minimum element in a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
       "array([0.43256084, 0.58404309, 0.8520027 , 0.52542086, 0.24696952,\n",
       "       0.19221685, 0.26257971, 0.20144448, 0.13381178, 0.56722572,\n",
       "       0.97093021, 0.15858283, 0.05143708, 0.73613208, 0.68998962,\n",
       "       0.36672821, 0.64479611, 0.02219078, 0.76275184, 0.33243255,\n",
       "       0.82880131, 0.93376971, 0.80755642, 0.84896572, 0.2924872 ,\n",
       "       0.09784432, 0.35448187, 0.31792348, 0.57771887, 0.00904141,\n",
       "       0.09170314, 0.60717953, 0.60001214, 0.3526583 , 0.6320709 ,\n",
       "       0.79486236, 0.37648065, 0.27198851, 0.48593869, 0.51071111,\n",
       "       0.39142415, 0.31623211, 0.494381  , 0.2140529 , 0.85118019,\n",
       "       0.41643056, 0.15296566, 0.15743329, 0.2458069 , 0.61907841])>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with 50 values between 0 and 1\n",
    "F = tf.constant(np.random.random((50)))\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=10>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the maximum element position of F\n",
    "tf.argmax(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=29>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the minimum element position of F\n",
    "tf.argmin(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value of F is at position: 10\n",
      "The maximum value of F is: 0.9709302080226296\n",
      "Using tf.argmax() to index F, the maximum value of F is: 0.9709302080226296\n",
      "Are the two max values the same (they should be)? True\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum element position of F\n",
    "print(f\"The maximum value of F is at position: {tf.argmax(F).numpy()}\") \n",
    "print(f\"The maximum value of F is: {tf.reduce_max(F).numpy()}\") \n",
    "print(f\"Using tf.argmax() to index F, the maximum value of F is: {F[tf.argmax(F)].numpy()}\")\n",
    "print(f\"Are the two max values the same (they should be)? {F[tf.argmax(F)].numpy() == tf.reduce_max(F).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezing a tensor (removing all single dimensions)\n",
    "If you need to remove single-dimensions from a tensor (dimensions with size 1), you can use tf.squeeze().\n",
    "\n",
    "tf.squeeze() - remove all dimensions of 1 from a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 1, 1, 1, 50]), 5)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 5 (5 dimensions) tensor of 50 numbers between 0 and 100\n",
    "G = tf.constant(np.random.randint(0, 100, 50), shape=(1, 1, 1, 1, 50))\n",
    "G.shape, G.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([50]), 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze tensor G (remove all 1 dimensions)\n",
    "G_squeezed = tf.squeeze(G)\n",
    "G_squeezed.shape, G_squeezed.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "If you have a tensor of indicies and would like to one-hot encode it, you can use tf.one_hot().\n",
    "\n",
    "You should also specify the depth parameter (the level which you want to one-hot encode to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of indices\n",
    "some_list = [0, 1, 2, 3]\n",
    "\n",
    "# One hot encode them\n",
    "tf.one_hot(some_list, depth=4)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify values for on_value and off_value instead of the default 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
       "array([[b'alive', b'dead', b'dead', b'dead'],\n",
       "       [b'dead', b'alive', b'dead', b'dead'],\n",
       "       [b'dead', b'dead', b'alive', b'dead'],\n",
       "       [b'dead', b'dead', b'dead', b'alive']], dtype=object)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify custom values for on and off encoding\n",
    "tf.one_hot(some_list, depth=4, on_value=\"alive\", off_value=\"dead\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squaring, log, square root\n",
    "\n",
    "Many other common mathematical operations you'd like to perform at some stage, probably exist.\n",
    "\n",
    "Let's take a look at:\n",
    "<ul>\n",
    "<li>tf.square() - get the square of every value in a tensor.\n",
    "<li>tf.sqrt() - get the squareroot of every value in a tensor (note: the elements need to be floats or this will error).\n",
    "<li>tf.math.log() - get the natural log of every value in a tensor (elements need to floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor\n",
    "H = tf.constant(np.arange(1, 10))\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([ 1,  4,  9, 16, 25, 36, 49, 64, 81])>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square it\n",
    "tf.square(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Find the squareroot (will error), needs to be non-integer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tf\u001b[39m.\u001b[39;49msqrt(H)\n",
      "File \u001b[1;32mc:\\Users\\vamsi\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\vamsi\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]"
     ]
    }
   ],
   "source": [
    "# Find the squareroot (will error), needs to be non-integer\n",
    "tf.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=float32)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change H to float32\n",
    "H = tf.cast(H, dtype=tf.float32)\n",
    "H  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([1.       , 1.4142135, 1.7320508, 2.       , 2.2360678, 2.4494896,\n",
       "       2.6457512, 2.828427 , 3.       ], dtype=float32)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the squareroot (will error), needs to be non-integer\n",
    "tf.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
       "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the log (input also needs to be float)\n",
    "tf.math.log(H)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and NumPy\n",
    "We've seen some examples of tensors interact with NumPy arrays, such as, using NumPy arrays to create tensors.\n",
    "\n",
    "Tensors can also be converted to NumPy arrays using:\n",
    "<ul>\n",
    "<li>np.array() - pass a tensor to convert to an ndarray (NumPy's main datatype).\n",
    "<li>tensor.numpy() - call on a tensor to convert to an ndarray.\n",
    "</ul>\n",
    "Doing this is helpful as it makes tensors iterable as well as allows us to use any of NumPy's methods on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor from a NumPy array\n",
    "J = tf.constant(np.array([3., 7., 10.]))\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor J to NumPy with np.array()\n",
    "np.array(J), type(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor J to NumPy with .numpy()\n",
    "J.numpy(), type(J.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default tensors have dtype=float32, where as NumPy arrays have dtype=float64.\n",
    "\n",
    "This is because neural networks (which are usually built with TensorFlow) can generally work very well with less precision (32-bit rather than 64-bit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor from NumPy and from an array\n",
    "numpy_J = tf.constant(np.array([3., 7., 10.])) # will be float64 (due to NumPy)\n",
    "tensor_J = tf.constant([3., 7., 10.]) # will be float32 (due to being TensorFlow default)\n",
    "numpy_J.dtype, tensor_J.dtype  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using @tf.function\n",
    "In your TensorFlow adventures, you might come across Python functions which have the decorator @tf.function.\n",
    "\n",
    "In short, decorators modify a function in one way or another.\n",
    "\n",
    "In the @tf.function decorator case, it turns a Python function into a callable TensorFlow graph. Which is a fancy way of saying, if you've written your own Python function, and you decorate it with @tf.function, when you export your code (to potentially run on another device), TensorFlow will attempt to convert it into a fast(er) version of itself (by making it part of a computation graph).\n",
    "\n",
    "For more on this, read the Better performnace with tf.function guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 10,  12,  16,  22,  30,  40,  52,  66,  82, 100])>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple function\n",
    "def function(x, y):\n",
    "  return x ** 2 + y\n",
    "\n",
    "x = tf.constant(np.arange(0, 10))\n",
    "y = tf.constant(np.arange(10, 20))\n",
    "function(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 10,  12,  16,  22,  30,  40,  52,  66,  82, 100])>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the same function and decorate it with tf.function\n",
    "@tf.function\n",
    "def tf_function(x, y):\n",
    "  return x ** 2 + y\n",
    "\n",
    "tf_function(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you noticed no difference between the above two functions (the decorated one and the non-decorated one) you'd be right.\n",
    "\n",
    "Much of the difference happens behind the scenes. One of the main ones being potential code speed-ups where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding access to GPUs\n",
    "We've mentioned GPUs plenty of times throughout this notebook.\n",
    "\n",
    "So how do you check if you've got one available?\n",
    "\n",
    "You can check if you've got access to a GPU using tf.config.list_physical_devices()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above outputs an empty array (or nothing), it means you don't have access to a GPU (or at least TensorFlow can't find it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 28 05:26:44 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.41                 Driver Version: 531.41       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti    WDDM | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   51C    P8                3W /  N/A|   2476MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     21760      C   ...\\vamsi\\anaconda3\\envs\\tf\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
