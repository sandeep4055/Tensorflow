{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-In Callbacks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow provides several built-in callbacks that can be used during model training to perform various tasks such as logging metrics, saving model checkpoints, early stopping, and more. Here are some of the most commonly used built-in callbacks in TensorFlow:\n",
    "\n",
    "1. **ModelCheckpoint:** This callback saves the model after every epoch, or after a certain number of training iterations. This helps in resuming the training from the same point in case the training gets interrupted.\n",
    "\n",
    "2. **EarlyStopping:** This callback monitors a metric of the validation data and stops the training process early if the metric doesn't improve for a certain number of epochs. It helps in preventing overfitting and saves time and resources.\n",
    "\n",
    "3. **TensorBoard:** This callback creates log files for visualization using TensorBoard, which can help in tracking the performance of the model.\n",
    "\n",
    "4. **ReduceLROnPlateau:** This callback reduces the learning rate of the optimizer if the monitored metric doesn't improve for a certain number of epochs. This can help in getting the model to converge faster.\n",
    "\n",
    "5. **LearningRateScheduler:** This callback allows you to set a custom learning rate schedule for the optimizer.\n",
    "\n",
    "6. **CSVLogger:** This callback logs the epoch results to a CSV file.\n",
    "\n",
    "7. **TerminateOnNaN:** This callback terminates the training process if it encounters NaN or infinite values.\n",
    "\n",
    "These are just a few examples of the built-in callbacks available in TensorFlow. They provide a lot of flexibility and can help in optimizing the training process of your models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use callbacks in TensorFlow, you can pass them as a parameter to the fit() method when training your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, TensorBoard\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "x_train = np.random.rand(1000, 10)\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "x_test = np.random.rand(100, 10)\n",
    "y_test = np.random.randint(2, size=(100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation for binary classification\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "inputs = Input(shape=(10,))\n",
    "x = Dense(32, activation='relu')(inputs)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ModelCheckpoint, EarlyStopping, CSVLogger, and TensorBoard callbacks by passing them to the fit() method of our model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 2s 18ms/step - loss: 0.6961 - accuracy: 0.5060 - val_loss: 0.6972 - val_accuracy: 0.5300\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6940 - accuracy: 0.5170 - val_loss: 0.6970 - val_accuracy: 0.4700\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6917 - accuracy: 0.5230 - val_loss: 0.6961 - val_accuracy: 0.4600\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.5180 - val_loss: 0.6946 - val_accuracy: 0.4600\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.5270 - val_loss: 0.6940 - val_accuracy: 0.4600\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6892 - accuracy: 0.5280 - val_loss: 0.6943 - val_accuracy: 0.4800\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6881 - accuracy: 0.5360 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6879 - accuracy: 0.5310 - val_loss: 0.6918 - val_accuracy: 0.5500\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6875 - accuracy: 0.5440 - val_loss: 0.6927 - val_accuracy: 0.5300\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.5320 - val_loss: 0.6924 - val_accuracy: 0.5400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1efbc032d40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, TensorBoard\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    EarlyStopping(patience=5),\n",
    "    CSVLogger('training.log'),\n",
    "    TensorBoard(log_dir='logs')\n",
    "]\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=10, \n",
    "          batch_size=32, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=callbacks)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this example, we are using the ModelCheckpoint callback to save the model weights after each epoch with a file name that includes the epoch number and validation loss. We are using the EarlyStopping callback to stop training if the validation loss does not improve for 5 epochs. We are using the CSVLogger callback to save the training and validation metrics to a CSV file. And we are using the TensorBoard callback to log the training and validation metrics to a TensorBoard directory.\n",
    "\n",
    "- After training, we can view the TensorBoard logs using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
