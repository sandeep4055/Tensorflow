{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Alexnet Model using Subclassing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructor\n",
    "\n",
    "- super(MyModel, self).__init__() is calling the __init__ method of the tf.keras.Model class, the base class of MyModel.\n",
    "\n",
    "- By calling the __init__ method of the base class, we are initializing the necessary components for our custom model. This includes creating an empty list to hold the layers of our model, setting the trainable attribute to True, and other necessary attributes.\n",
    "\n",
    "- The super() function returns a temporary object of the superclass, which allows you to call its methods. In this case, we are calling the __init__ method of the superclass, tf.keras.Model. We pass MyModel and self as arguments to the super() function, which allows us to call the __init__ method of the superclass with the self argument.\n",
    "\n",
    "## Input Layer\n",
    "In a neural network, the input layer is the first layer of the network that receives the input data. It serves as a pass-through layer that simply passes the input data to the first hidden layer of the network. The input layer is typically defined to have the same shape as the input data, and each neuron in the input layer corresponds to a feature or attribute of the input data.\n",
    "\n",
    "For example, in an image classification task, the input layer of a neural network would have neurons corresponding to each pixel in the input image. The number of neurons in the input layer is equal to the product of the height, width, and depth (number of channels) of the input image.\n",
    "\n",
    "In TensorFlow, an input layer can be created using the tf.keras.layers.Input function or the tf.keras.Input function. The input layer is typically the first layer in the model's architecture, and its output is passed to the next layer in the model.\n",
    "\n",
    "\n",
    "- **tf.keras.layers.Input** is a layer class that can be used to create an input layer in a functional API model. It takes a shape argument that specifies the shape of the input data.\n",
    "\n",
    "- **tf.keras.Input** is a function that returns a symbolic tensor, which can be used as the input to a Keras model. It also takes a shape argument that specifies the shape of the input data.\n",
    "\n",
    "- Both tf.keras.layers.Input and tf.keras.Input can be used to create an input layer in a TensorFlow model. The difference between them is that tf.keras.layers.Input is a layer class that can be added to a model like any other layer, whereas tf.keras.Input is a function that returns a tensor object that can be passed to other layers in a model.\n",
    "\n",
    "# Specifying Activation\n",
    "\n",
    "In TensorFlow, there are several ways to specify activation functions for a layer:\n",
    "\n",
    "- Using a string name: The name of the activation function can be specified as a string when defining a layer. For example, tf.keras.layers.Dense(64, activation='relu') would create a fully connected layer with 64 units and a ReLU activation function.The advantage of this method is its simplicity and ease of use. TensorFlow provides a variety of activation functions that can be used in this way, including \"relu\", \"sigmoid\", \"tanh\", \"softmax\", and more.\n",
    "\n",
    "Under the hood, when a layer object is initialized with a string for the activation parameter, TensorFlow will automatically create an instance of the corresponding activation function and use it as the activation function for the layer. This is done using TensorFlow's built-in get_activation function, which maps string names to activation functions.\n",
    "\n",
    "- Using a callable: A callable function can also be passed as the activation argument when defining a layer. For example, tf.keras.layers.Dense(64, activation=tf.nn.relu) would create a fully connected layer with 64 units and a ReLU activation function defined using the tf.nn.relu function.\n",
    "\n",
    "- Using the activation method: The activation method of a layer object can be used to specify the activation function for that layer after it has been created. For example, layer.activation = tf.nn.relu would set the activation function for the layer object to the ReLU function.\n",
    "\n",
    "- Using a separate activation layer: In some cases, it may be desirable to separate the activation function from the layer itself. This can be done by creating a separate activation layer and specifying it as a separate layer in the model. For example, tf.keras.layers.Dense(64) would create a fully connected layer with 64 units, and tf.keras.layers.Activation('relu') would create a separate activation layer with a ReLU activation function. These layers could then be combined in the model using the functional API.\n",
    "\n",
    "## Call method\n",
    "\n",
    "- In TensorFlow, the call method is a special method defined in a Keras model or layer class that specifies the computation performed by the model or layer. When you call a Keras model or layer object with an input tensor, the call method is invoked to perform the forward pass computation and generate the output tensor.\n",
    "\n",
    "- The call method takes an input tensor as its argument and returns an output tensor. It specifies the computation that should be performed on the input tensor to produce the output tensor. This computation typically involves applying a series of transformations to the input tensor using weights and biases stored in the model or layer object.\n",
    "\n",
    "- The call method is where the actual work of the model or layer is done, so it is a critical component of any Keras model or layer. By defining the call method for your model or layer class, you can specify exactly how the model or layer should behave when it is called with input data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using subclassing technique\n",
    "class AlexNet(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        # input layer , input_shape = (224,224,3)\n",
    "        self.input_layer = tf.keras.layers.InputLayer(input_shape=(None,224,224,3))\n",
    "\n",
    "        # Conv1 filters=96, size= 11*11, stride= 4, activation= relu\n",
    "        self.conv1 = tf.keras.layers.Conv2D( filters=96,\n",
    "                                       kernel_size=(11,11),\n",
    "                                       strides=4,\n",
    "                                       activation=\"relu\"\n",
    "                                       )\n",
    "        \n",
    "        #maxpool1 size=5*5, stride=2\n",
    "        self.maxpool1 = tf.keras.layers.MaxPool2D(pool_size=(5,5), strides=2)\n",
    "\n",
    "        # Conv2 filters=256, size= 5*5, stride= 1, padding=2 ,activation= relu\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=256,\n",
    "                                       kernel_size=(5,5),\n",
    "                                       strides=1,\n",
    "                                       padding=\"same\",\n",
    "                                       activation=\"relu\")\n",
    "        \n",
    "        #maxpool2 size=3*3, stride=2\n",
    "        self.maxpool2 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2)\n",
    "\n",
    "        # Conv3 filters=384, size= 3*3, stride= 1, padding=1 ,activation= relu\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=384,\n",
    "                                       kernel_size=(3,3),\n",
    "                                       strides=1,\n",
    "                                       padding=\"same\",\n",
    "                                       activation=\"relu\")\n",
    "        \n",
    "        # Conv4 filters=384, size= 3*3, stride= 1, padding=1 ,activation= relu\n",
    "        self.conv4 = tf.keras.layers.Conv2D(filters=384,\n",
    "                                       kernel_size=(3,3),\n",
    "                                       strides=1,\n",
    "                                       padding=\"same\",\n",
    "                                       activation=\"relu\")\n",
    "        \n",
    "        # Conv5 filters=256, size= 3*3, stride= 1, padding=1 ,activation= relu\n",
    "        self.conv5 = tf.keras.layers.Conv2D(filters=256,\n",
    "                                       kernel_size=(3,3),\n",
    "                                       strides=1,\n",
    "                                       padding=\"same\",\n",
    "                                       activation=\"relu\")\n",
    "        \n",
    "        #maxpool3 size=3*3, stride=2\n",
    "        self.maxpool3 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2)\n",
    "\n",
    "        #dropout rate=0.5\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate=0.5)\n",
    "\n",
    "        # Fully Connected Layer filetrs=4096 , activation= relu\n",
    "        self.fully_connected1 = tf.keras.layers.Dense(units=4096, activation=\"relu\")\n",
    "\n",
    "        #droput rate=0.5\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate=0.5)\n",
    "\n",
    "        # Fully Connected Layer filetrs=4096 , activation= relu\n",
    "        self.fully_connected2 = tf.keras.layers.Dense(units=4096, activation=\"relu\")\n",
    "\n",
    "        # Fully Connected Layer filetrs=1000 , activation= softmax\n",
    "        self.output_layer = tf.keras.layers.Dense(units=1000, activation=\"softmax\")\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fully_connected1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fully_connected2(x)\n",
    "        output = self.output_layer(x)      \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"alex_net_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, None, 224, 224,   0         \n",
      "                             3)]                                 \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          multiple                  34944     \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          multiple                  614656    \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          multiple                  885120    \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          multiple                  1327488   \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          multiple                  884992    \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            multiple                  1052672   \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            multiple                  16781312  \n",
      "                                                                 \n",
      " dense_29 (Dense)            multiple                  4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,678,184\n",
      "Trainable params: 25,678,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "input_shape = (None,224, 224, 3)\n",
    "model.build(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_input_shape': (None, None, 224, 224, 3), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_16'}\n",
      "{'name': 'conv2d_57', 'trainable': True, 'dtype': 'float32', 'filters': 96, 'kernel_size': (11, 11), 'strides': (4, 4), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'max_pooling2d_33', 'trainable': True, 'dtype': 'float32', 'pool_size': (5, 5), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}\n",
      "{'name': 'conv2d_58', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (5, 5), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'max_pooling2d_34', 'trainable': True, 'dtype': 'float32', 'pool_size': (3, 3), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}\n",
      "{'name': 'conv2d_59', 'trainable': True, 'dtype': 'float32', 'filters': 384, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_60', 'trainable': True, 'dtype': 'float32', 'filters': 384, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_61', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'max_pooling2d_35', 'trainable': True, 'dtype': 'float32', 'pool_size': (3, 3), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}\n",
      "{'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}\n",
      "{'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 4096, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}\n",
      "{'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 4096, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 1000, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n"
     ]
    }
   ],
   "source": [
    "# Print layer configurations\n",
    "for layer in model.layers:\n",
    "    print(layer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHkAAAA8CAIAAADNDYLBAAAABmJLR0QA/wD/AP+gvaeTAAADnklEQVR4nO2cvU7rMBSAj694hm4w8gzNEzClUxDqjqoOsMAa1AHGwApq2Dqk/GyZy8CSjGUsm0EMzoCSJzCDRZTmryEJh6r3fBMxJ8fHX4xtpRVMSgkECv/+uoD/CHKNB7nGg1zjsZW88Dzv6urqr0rZPDRNOzk5iS+X5vX7+/vj4yN6SZuJ7/ue5yVbtrJBDw8PWPVsMvv7+6kWWq/xINd4kGs8yDUe5BoPco0HucaDXONBrvEg13iQazzINR7kGg9yjUdrroMgmE6nvV6vrYSbR2uuR6NRv993XbethM2JoogxVjHS933btsvnim3bFRPmkvNZQT2ur69vbm7aytYKz8/PFSMtywKAi4uLkpiXl5fBYNCkntZcrxtRFNm2XTH4/PwcSl1HUdT808E6a4gaBmOMMXZ2dhYEQVFkEASXl5eMsV6v9/T0BAAsQfayJE+8GbiuqxK+vb2VdGRZllrQViavwu3t7fHxccMkIBPc3d2lWnIZDocAIITgnAPAcDhU7amEQghd1x3HkVLOZjMAmM/nUsrxeKxuj2NUewm6rqvknudJKVP9FnWUHWA5RfGz2Uz1+6OEhmEYhrGUP3lR0bVpmrl+U6U4jpO8BADTNNXP8dOyLEtJX0kqefKyqKNWXAshxuNxSUAR7bhWcM7VllLkOp6M2T8jIQQA6Lq+WCwqdlfiuqijVlzHon+aMOu65pnPtu2jo6PcQcao5TJ3PJ1Ox3Ec13U/Pz/rFVCxo+aZ9/b2WkkF9c4h0+l0MBhwznd2dlYGv76+7u7uphqDIPj4+LAsS9M0IUSn06lRRpWOGpJ73GaM1XuWdeZ1v98HgJWi1R44mUyiKILvo4L61WQyOT09PTw81HV9NBrVqKFiRw0pWmRaSFdxvVZLB+d8sVioJEIItQTD9wFDfi/KSTjnYRiaphmGoYoJwxASe2YRcSp1o7oLEoeZbEdxnWoHXjmoOGdcW5bcB1BEO3vjfD5XgoQQ6kyiDmHZ58c5N00TAFSMTMyIZPUrx5AKy96V7ShVZ/mIyqdgKmylH0XW9dLSc39/f3BwkNs38VPU9/mSX46kd6p4kGs81ujdU/lbi4Yr268mr8gauf7VAa/DJkRrCB7kGg9yjQe5xoNc40Gu8SDXeJBrPMg1HuQaD3KNB7nGg1zjkfOeL/sPAoga+L7f7XaTLUvzent72zAM3JI2lm63q2lasqXmVx2IGtB6jQe5xoNc40Gu8fgCJNBG7T7o7LcAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "# Visualize the model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
